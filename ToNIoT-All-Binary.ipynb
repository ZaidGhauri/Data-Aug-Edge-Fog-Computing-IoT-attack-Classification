{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def readDataSets():\n",
    "    dataSetFridge = pd.read_csv(filepath_or_buffer = 'data/ToNIoT/binary/IoT_Fridge.csv')\n",
    "    dataSetGarageDoor = pd.read_csv(filepath_or_buffer = 'data/ToNIoT/binary/IoT_Garage_Door.csv')\n",
    "    dataSetGPS = pd.read_csv(filepath_or_buffer = 'data/ToNIoT/binary/IoT_GPS_Tracker.csv')\n",
    "    dataSetModbus = pd.read_csv(filepath_or_buffer = 'data/ToNIoT/binary/IoT_Modbus.csv')\n",
    "    dataSetMotionLight = pd.read_csv(filepath_or_buffer = 'data/ToNIoT/binary/IoT_Motion_Light.csv')\n",
    "    dataSetThermostat = pd.read_csv(filepath_or_buffer = 'data/ToNIoT/binary/IoT_Thermostat.csv')\n",
    "    dataSetWeahter = pd.read_csv(filepath_or_buffer = 'data/ToNIoT/binary/IoT_Weather.csv')\n",
    "\n",
    "    dataSetFridge['temp_condition'] = dataSetFridge['temp_condition'].str.strip()\n",
    "    dataSetGarageDoor['door_state'] = dataSetGarageDoor['door_state'].str.strip()\n",
    "    dataSetMotionLight['light_status'] = dataSetMotionLight['light_status'].str.strip()\n",
    "    dataSetRawLoad = pd.concat([dataSetFridge, dataSetGarageDoor, dataSetGPS, dataSetModbus, dataSetMotionLight, dataSetThermostat, dataSetWeahter])\n",
    "    \n",
    "    dataSetRawLoad1=pd.DataFrame()\n",
    "    label=LabelEncoder()\n",
    "    for c in  dataSetRawLoad.columns:\n",
    "        if(dataSetRawLoad[c].dtype=='object'):\n",
    "            dataSetRawLoad1[c]=label.fit_transform(dataSetRawLoad[c])\n",
    "        else:\n",
    "            dataSetRawLoad1[c]=dataSetRawLoad[c]\n",
    "\n",
    "    print('dataSetRawLoad: ', dataSetRawLoad1.shape)\n",
    "    return dataSetRawLoad1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readDataSets()\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "df.head()\n",
    "\n",
    "a = pd.DataFrame(df['label'].value_counts())[:]\n",
    "a.plot(kind='pie', subplots=True, figsize=(5, 5))\n",
    "plt.title('ToN-IoT Dataset Attacks')\n",
    "plt.legend(loc='left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df['label'].value_counts())[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "categorical_features = ['label', 'door_state','sphone_signal', 'light_status','temp_condition']\n",
    "quantitative_features = ['FC1_Read_Input_Register','FC2_Read_Discrete_Value','FC3_Read_Holding_Register','FC4_Read_Coil','current_temperature',\n",
    "                        'fridge_temperature','humidity','latitude','FC4_Read_Coil','longitude',\n",
    "                        'motion_status','pressure','temperature','thermostat_status']\n",
    "features = categorical_features + quantitative_features\n",
    "\n",
    "def datapreprocessingShuffle(data):\n",
    "               \n",
    "    # Feature scaling\n",
    "    for i in quantitative_features :\n",
    "            scaler = StandardScaler()\n",
    "            data[i] = scaler.fit_transform(data[[i]])\n",
    "            \n",
    "    # Encoding categorical features    \n",
    "    for i in categorical_features : \n",
    "        labelencoder=LabelEncoder()\n",
    "        data[i]=labelencoder.fit_transform(data[i])   \n",
    "    \n",
    "    data = shuffle(data).reset_index(drop=True) \n",
    "    \n",
    "    Y = data.loc[:,'label']\n",
    "    X = data.drop(['label'],axis=1) \n",
    "    \n",
    "    return(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing datset\n",
    "datacopy = df.copy()\n",
    "X, y = datapreprocessingShuffle(datacopy) \n",
    "\n",
    "X = X.fillna(X.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "normalized_arr = preprocessing.normalize(X)\n",
    "normalized_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting():\n",
    "    # define the base models\n",
    "    models = list()\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('CART', DecisionTreeRegressor()))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('MLP', MLPClassifier()))\n",
    "    models.append(('DT', DecisionTreeClassifier()))\n",
    "    models.append(('RF', RandomForestClassifier()))\n",
    "    models.append(('LR', LogisticRegression()))\n",
    "    models.append(('SVM', svm.SVC()))\n",
    "    models.append(('AdaBoost', AdaBoostClassifier()))\n",
    "    models.append(('GradientBoosting', GradientBoostingClassifier()))\n",
    "    models.append(('XGB', XGBClassifier()))\n",
    "    # define the voting ensemble\n",
    "    ensemble = VotingClassifier(estimators=models, voting='soft')\n",
    "    return ensemble\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('CART', DecisionTreeRegressor()))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('MLP', MLPClassifier()))\n",
    "    models.append(('DT', DecisionTreeClassifier()))\n",
    "    models.append(('RF', RandomForestClassifier()))\n",
    "    models.append(('LR', LogisticRegression()))\n",
    "    models.append(('SVM', svm.SVC()))\n",
    "    models.append(('AdaBoost', AdaBoostClassifier()))\n",
    "    models.append(('GradientBoosting', GradientBoostingClassifier()))\n",
    "    models.append(('XGB', XGBClassifier()))\n",
    "    models.append(('soft_voting', get_voting()))\n",
    "    return models\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models:\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('AdaBoost', AdaBoostClassifier()))\n",
    "models.append(('GradientBoosting', GradientBoostingClassifier()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('SVM', svm.SVC()))\n",
    "\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    print('asd')\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('AdaBoost', AdaBoostClassifier()))\n",
    "models.append(('GradientBoosting', GradientBoostingClassifier()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('SVM', svm.SVC()))\n",
    "\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)\n",
    "           #,'auc-score' : make_scorer(roc_auc_score)\n",
    "          }\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    start = time.time()\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_validate(model, normalized_arr, y, cv=kfold, scoring=scoring)\n",
    "    end = time.time()\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    print(name)\n",
    "    print(end - start, \"seconds\")\n",
    "    #print(cv_results)\n",
    "    print(np.mean(cv_results['test_accuracy']))\n",
    "    print(np.mean(cv_results['test_precision']))\n",
    "    print(np.mean(cv_results['test_recall']))\n",
    "    print(np.mean(cv_results['test_f1_score']))\n",
    "    #print(np.mean(cv_results['test_auc-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('AdaBoost', AdaBoostClassifier()))\n",
    "models.append(('GradientBoosting', GradientBoostingClassifier()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('SVM', svm.SVC()))\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)\n",
    "           #,'auc-score' : make_scorer(roc_auc_score)\n",
    "          }\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    start = time.time()\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    cv_results = cross_validate(model, normalized_arr, y, cv=kfold, scoring=scoring)\n",
    "    end = time.time()\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    print(name)\n",
    "    print(end - start, \"seconds\")\n",
    "    #print(cv_results)\n",
    "    print(np.mean(cv_results['test_accuracy']))\n",
    "    print(np.mean(cv_results['test_precision']))\n",
    "    print(np.mean(cv_results['test_recall']))\n",
    "    print(np.mean(cv_results['test_f1_score']))\n",
    "    #print(np.mean(cv_results['test_auc-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('AdaBoost', AdaBoostClassifier()))\n",
    "models.append(('GradientBoosting', GradientBoostingClassifier()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('SVM', svm.SVC()))\n",
    "\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    cv_results = cross_validate(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    #print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    print(name)\n",
    "    #print(cv_results)\n",
    "    print(np.mean(cv_results['test_accuracy']))\n",
    "    print(np.mean(cv_results['test_precision']))\n",
    "    print(np.mean(cv_results['test_recall']))\n",
    "    print(np.mean(cv_results['test_f1_score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
